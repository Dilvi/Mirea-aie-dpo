# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Выбран датасет: `S06-hw-dataset-02.csv`
- Размер датасета: ~3000 строк, ~20 признаков
- Целевая переменная: `target` (бинарная классификация, умеренный дисбаланс классов)
- Признаки:
  - в основном числовые признаки;
  - присутствуют несколько признаков с малым числом уникальных значений, которые можно рассматривать как категориальные-подобные (удобно для деревьев).

Датасет содержит нелинейные зависимости и шум, что делает его подходящим для сравнения деревьев и ансамблей.

---

## 2. Protocol

- Разбиение данных:
  - train / test = 75% / 25%
  - `random_state = 42`
  - `stratify = y` для сохранения баланса классов

- Подбор гиперпараметров:
  - выполнялся **только на train**
  - использовался `GridSearchCV` с 5-фолдовой кросс-валидацией
  - оптимизировалась метрика **ROC-AUC**

- Метрики качества:
  - **accuracy** — базовая метрика классификации;
  - **F1-score** — учитывает баланс precision/recall;
  - **ROC-AUC** — ключевая метрика для бинарной классификации, устойчива к дисбалансу классов и отражает качество ранжирования вероятностей.

---

## 3. Models

В эксперименте были сравнены следующие модели:

- **DummyClassifier**
  - baseline (most_frequent)
  - используется как нижняя точка отсчёта

- **LogisticRegression**
  - baseline из HW05
  - использован `Pipeline(StandardScaler + LogisticRegression)`
  - без сложного подбора параметров

- **DecisionTreeClassifier**
  - контроль сложности через:
    - `max_depth`
    - `min_samples_leaf`
  - параметры подбирались через GridSearchCV

- **RandomForestClassifier**
  - ансамбль деревьев (bagging + случайность по признакам)
  - подбирались:
    - `n_estimators`
    - `max_depth`
    - `min_samples_leaf`

- **GradientBoostingClassifier**
  - boosting-модель
  - использовалась как представитель последовательных ансамблей

---

## 4. Results

Финальные метрики на test:

| Model            | Accuracy | F1-score | ROC-AUC |
|------------------|----------|----------|---------|
| Dummy            | 0.7375   | 0.0000   | 0.5000  |
| LogisticRegression | 0.8119 | 0.5607   | 0.7977  |
| DecisionTree     | 0.8383   | 0.6576   | 0.8371  |
| RandomForest     | **0.8906** | **0.7556** | **0.9262** |
| GradientBoosting | 0.8689   | 0.7076   | 0.8962  |

**Победитель:** `RandomForestClassifier`

Он показал наилучшие значения ROC-AUC и F1-score, что говорит о хорошем качестве ранжирования и балансе ошибок.

---

## 5. Analysis

### Устойчивость

Для RandomForest и DecisionTree при изменении `random_state` наблюдались небольшие колебания метрик, однако RandomForest оставался лучшей моделью по ROC-AUC, что говорит о его устойчивости.

### Ошибки

Confusion matrix для RandomForest показывает:
- заметное снижение числа false negatives по сравнению с baseline-моделями;
- более сбалансированное распределение ошибок между классами.

### Интерпретация

Permutation importance для RandomForest показала, что наибольший вклад в качество модели вносят:
- несколько ключевых числовых признаков (топ-10 по importance);
- признаки, связанные с нелинейными взаимодействиями.

Это ожидаемо для ансамбля деревьев, который хорошо захватывает сложные зависимости в данных.

---

## 6. Conclusion

- Одиночные деревья легко переобучаются, но контроль сложности существенно улучшает их качество.
- Bagging (RandomForest) эффективно снижает variance и даёт стабильный прирост качества.
- Boosting показывает высокое качество, но чувствительнее к шуму.
- Ансамбли уверенно превосходят линейные модели на нелинейных данных.
- Честный ML-протокол (фиксированный split, CV только на train, единые метрики) критически важен для корректного сравнения моделей.
